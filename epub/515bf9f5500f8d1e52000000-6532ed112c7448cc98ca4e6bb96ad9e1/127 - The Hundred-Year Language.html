<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html lang="en"><head><title>
   The Hundred-Year Language
  </title></head><body>
  <a target="_blank" href="http://ep.yimg.com/ca/I/paulgraham_2202_10513175">
   <img border="0" height="110" hspace="0" src="http://ep.yimg.com/ca/I/paulgraham_2202_10547098" vspace="0" width="410"></a>
  <h2>
   <h1><span class="s s1">
    The Hundred-Year Language
   </span></h1>
   </h2><p><span class="s s2">
    April 2003
   </span></p>
   <p><span class="s s3">
    <i>
     (This essay is derived from a keynote talk at PyCon 2003.)
    </i>
   </span></p>
   <p>
    <span class="s s4">It's hard to predict what
life will be like in a hundred years.</span>  <span class="s s5">There are only a few
things we can say with certainty.</span>  <span class="s s6">We know that everyone will
drive flying cars,
that zoning laws will be relaxed to allow buildings
hundreds of stories tall, that it will be dark most of the
time, and that women will all be trained in the martial arts.</span>  
<span class="s s7">Here I want to zoom in on one detail of this
picture.</span>  <span class="s s8">What kind of programming language will they use to
write the software controlling those flying cars?</span>
   </p>
   <p>
    <span class="s s10">This is worth thinking about not so
much because we'll actually get to use these languages as because,
if we're lucky, we'll use languages on the path from this
point to that.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s12">I think that, like species, languages will form evolutionary trees,
with dead-ends branching off all over.</span>  <span class="s s13">We can see this
happening already.</span>
<span class="s s14">Cobol, for all its sometime popularity, does not seem to have any
intellectual descendants.</span>  <span class="s s15">It is an evolutionary dead-end-- a
Neanderthal language.</span>
   </p>
   <p>
    <span class="s s17">I predict a similar fate for Java.</span>  <span class="s s18">People
sometimes send me mail saying, "How can you say that Java
won't turn out to be a successful language?</span>  <span class="s s19">It's already
a successful language.</span><span class="s s20">"</span>  <span class="s s21">And I admit that it is, if you
measure success by shelf space taken up by books on it
(particularly individual books on it), or by
the number of undergrads who believe they have to
learn it to get a job.</span>  <span class="s s22">When I say Java won't
turn out to be a successful language, I mean something more
specific:  that Java
will turn out to be an evolutionary dead-end, like Cobol.</span>
   </p>
   <p>
    <span class="s s24">This is just a guess.</span>  <span class="s s25">I may be wrong.</span>  <span class="s s26">My point here is not to dis Java,
but to raise the issue of evolutionary
trees and get people asking, where on the tree is language X?</span>
<span class="s s27">The reason to ask this question isn't just so that
our ghosts can say, in a
hundred years, I told you so.</span>  <span class="s s28">It's because staying close to  
the main branches is a useful heuristic for finding languages that will
be good to program in now.</span>
   </p>
   <p>
    <span class="s s30">At any given time, you're probably happiest on
the main branches of an evolutionary tree.</span>
<span class="s s31">Even when there were still plenty of Neanderthals, 
it must have sucked to be one.</span>  <span class="s s32">The
Cro-Magnons would have been constantly coming over and
beating you up and stealing your food.</span>
   </p>
   <p><span class="s s34">
    The reason I want to
know what languages will be like in a hundred years is so that
I know what branch of the tree to bet on now.
   </span></p>
   <p>
   </p>
   <p>
    <span class="s s35">The evolution of languages differs from the evolution of species
because branches can converge.</span>  <span class="s s36">The Fortran branch, for example,
seems to be merging with the descendants
of Algol.</span>  <span class="s s37">In theory this is possible for species too, but it's
not likely to have happened to any bigger than a cell.</span>
   </p>
   <p>
    <span class="s s39">Convergence
is more likely for languages partly because the space of
possibilities is smaller, and partly because mutations
are not random.</span>  <span class="s s40">Language designers deliberately incorporate
ideas from other languages.</span>
   </p>
   <p>
    <span class="s s42">It's especially useful for language designers to think
about where the evolution of programming languages is likely
to lead, because they can steer accordingly.</span> 
<span class="s s43">In that case, "stay on a main branch" becomes more than a
way to choose a good language.</span>
<span class="s s44">It becomes a heuristic for making the right decisions about
language design.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s46">Any programming language can be divided into
two parts:  some set of fundamental operators that play the role
of axioms, and the rest of the language, which could in principle
be written in terms of these fundamental operators.</span>
   </p>
   <p>
    <span class="s s48">I think the fundamental operators are the most important factor in a
language's long term survival.</span>  <span class="s s49">The rest you can change.</span>  <span class="s s50">It's
like the rule that in buying a house you should consider
location first of all.</span>  <span class="s s51">Everything else you can fix later, but you
can't fix the location.</span>
   </p>
   <p>
    <span class="s s53">I think it's important not just that the axioms be well chosen, 
but that there be few of them.</span>  <span class="s s54">Mathematicians have always felt 
this way about axioms-- the fewer, the better-- and I think they're
onto something.</span>
   </p>
   <p>
    <span class="s s56">At the very least, it has to be a useful exercise to look closely
at the core of a language to see if there are any axioms that
could be weeded out.</span>  <span class="s s57">I've found in my long career as a slob that
cruft breeds cruft, and I've seen this happen in software as
well as under beds and in the corners of rooms.</span>
   </p>
   <p>
    <span class="s s58">I have a hunch that
the main branches of the evolutionary tree pass through the languages
that have the smallest, cleanest cores.</span>
<span class="s s59">The more of a language you can write in itself,
the better.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s61">Of course, I'm making a big assumption in even asking what
programming languages will be like in a hundred years.</span>
<span class="s s62">Will we even be writing programs in a hundred years?</span>  <span class="s s63">Won't
we just tell computers what we want them to do?</span>
   </p>
   <p>
    <span class="s s65">There hasn't been a lot of progress in that department
so far.</span>
<span class="s s66">My guess is that a hundred years from now people will
still tell computers what to do using programs we would recognize
as such.</span>  <span class="s s67">There may be tasks that we
solve now by writing programs and which in a hundred years
you won't have to write programs to solve, but I think
there will still be a good deal of
programming of the type that we do today.</span>
   </p>
   <p>
    <span class="s s69">It may seem presumptuous to think anyone can predict what
any technology will look like in a hundred years.</span>  <span class="s s70">But
remember that we already have almost fifty years of history behind us.</span>
<span class="s s71">Looking forward a hundred years is a graspable idea
when we consider how slowly languages have evolved in the
past fifty.</span>
   </p>
   <p>
    <span class="s s73">Languages evolve slowly because they're not really technologies.</span>
<span class="s s74">Languages are notation.</span>  <span class="s s75">A program is a formal description of 
the problem you want a computer to solve for you.</span>  <span class="s s76">So the rate
of evolution in programming languages is more like the
rate of evolution in mathematical notation than, say,
transportation or communications.</span>
<span class="s s77">Mathematical notation does evolve, but not with the giant
leaps you see in technology.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s79">Whatever computers are made of in a hundred years, it seems  
safe to predict they will be much faster than
they are now.</span>  <span class="s s80">If Moore's Law continues to put out, they will be 74
quintillion (73,786,976,294,838,206,464) times faster.</span>  <span class="s s81">That's kind of
hard to imagine.</span>  <span class="s s82">And indeed, the most likely prediction in the
speed department may be that Moore's Law will stop working.</span>
<span class="s s83">Anything that is supposed to double every eighteen months seems
likely to run up against some kind of fundamental limit eventually.</span>
<span class="s s84">But I have no trouble believing that computers will be very much
faster.</span> <span class="s s85">Even if they only end up being a paltry million
times faster, that should change the ground rules for programming
languages substantially.</span>  <span class="s s86">Among other things, there
will be more room for what
would now be considered slow languages, meaning languages
that don't yield very efficient code.</span>
   </p>
   <p>
    <span class="s s88">And yet some applications will still demand speed.</span>
<span class="s s89">Some of the problems we want to solve with
computers are created by computers; for example, the
rate at which you have to process video images depends
on the rate at which another computer can
generate them.</span>  <span class="s s90">And there is another class of problems
which inherently have an unlimited capacity to soak up cycles:
image rendering, cryptography, simulations.</span>
   </p>
   <p>
    <span class="s s92">If some applications can be increasingly inefficient while
others continue to demand all the speed the hardware can
deliver, faster computers will mean that languages have
to cover an ever wider range of efficiencies.</span>  <span class="s s93">We've seen
this happening already.</span>  <span class="s s94">Current implementations of some
popular new languages are shockingly wasteful by the
standards of previous decades.</span>
   </p>
   <p>
    <span class="s s96">This isn't just something that happens with programming
languages.</span>  <span class="s s97">It's a general historical trend.</span>  <span class="s s98">As technologies improve,
each generation can do things that the previous generation
would have considered wasteful.</span>  <span class="s s99">People thirty years ago would
be astonished at how casually we make long distance phone calls.</span>
<span class="s s100">People a hundred years ago would be even more astonished that 
a package would one day travel from Boston to New York via Memphis.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s102">I can already tell you what's going to happen to all those extra
cycles that faster hardware is going to give us in the   
next hundred years.</span>  <span class="s s103">They're nearly all going to be wasted.</span>
   </p>
   <p>
    <span class="s s105">I learned to program when computer power was scarce.</span>
<span class="s s106">I can remember taking all the spaces out of my Basic programs
so they would fit into the memory of a 4K TRS-80.</span>  <span class="s s107">The
thought of all this stupendously inefficient software
burning up cycles doing the same thing over and over seems
kind of gross to me.</span>  <span class="s s108">But I think my intuitions here are wrong.</span>  <span class="s s109">I'm
like someone who grew up poor, and can't bear to spend money
even for something important, like going to the doctor.</span>
   </p>
   <p>
    <span class="s s111">Some kinds of waste really are disgusting.</span>  <span class="s s112">SUVs, for example, would
arguably be gross even if they ran on a fuel which would never
run out and generated no pollution.</span>  <span class="s s113">SUVs are gross because they're
the solution to a gross problem.</span> <span class="s s114">(How to make minivans look more
masculine.</span><span class="s s115">)
But not all waste is bad.</span>  <span class="s s116">Now that we have the infrastructure
to support it, counting the minutes of your long-distance
calls starts to seem niggling.</span>   <span class="s s117">If you have the
resources, it's more elegant to think of all phone calls as
one kind of thing, no matter where the other person is.</span>
   </p>
   <p>
    <span class="s s119">There's good waste, and bad waste.</span>  <span class="s s120">I'm interested
in good waste-- the kind where, by spending more, we can get  
simpler designs.</span>  <span class="s s121">How will we take advantage of the opportunities
to waste cycles that we'll get from new, faster hardware?</span>
   </p>
   <p>
    <span class="s s123">The desire for speed is so deeply engrained in us, with 
our puny computers, that it will take a conscious effort
to overcome it.</span>  <span class="s s124">In language design, we should be consciously seeking out
situations where we can trade efficiency for even the
smallest increase in convenience.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s126">Most data structures exist because of speed.</span>  <span class="s s127">For example,
many languages today have both strings and lists.</span>  <span class="s s128">Semantically, strings
are more or less a subset of lists in which the elements are
characters.</span>  <span class="s s129">So why do you need a separate data type?</span>
<span class="s s130">You don't, really.</span>  <span class="s s131">Strings only
exist for efficiency.</span>  <span class="s s132">But it's lame to clutter up the semantics
of the language with hacks to make programs run faster.</span>
<span class="s s133">Having strings in a language seems to be a case of
premature optimization.</span>
   </p>
   <p>
    <span class="s s135">If we think of the core of a language as a set of axioms,  
surely it's gross to have additional axioms that add no expressive
power, simply for the sake of efficiency.</span>  <span class="s s136">Efficiency is
important, but I don't think that's the right way to get it.</span>
   </p>
   <p>
    <span class="s s138">The right way to solve that problem, I think, is to separate
the meaning of a program from the implementation details.</span> 
<span class="s s139">Instead of having both lists and strings, have just lists,
with some way to give the compiler optimization advice that 
will allow it to lay out strings as contiguous bytes if
necessary.</span>
   </p>
   <p>
    <span class="s s141">Since speed doesn't matter in most of a program, you won't
ordinarily need to bother with
this sort of micromanagement.</span>
<span class="s s142">This will be more and more true as computers get faster.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s144">Saying less about implementation should also make programs
more flexible.</span>
<span class="s s145">Specifications change while a program is being written, and this is not
only inevitable, but desirable.</span>
   </p>
   <p>
    <span class="s s147">The word "essay" comes
from the French verb "essayer", which means "to try".</span>
<span class="s s148">An essay, in the original sense, is something you
write to try to figure something out.</span>  <span class="s s149">This happens in
software too.</span>  <span class="s s150">I think some of the best programs were essays,
in the sense that the authors didn't know when they started
exactly what they were trying to write.</span>
   </p>
   <p>
    <span class="s s152">Lisp hackers already know about the value of being flexible
with data structures.</span>  <span class="s s153">We tend to write the first version of
a program so that it does everything with lists.</span>  <span class="s s154">These
initial versions can be so shockingly inefficient that it
takes a conscious effort not to think about what they're
doing, just as, for me at least, eating a steak requires a
conscious effort not to think where it came from.</span>
   </p>
   <p>
    <span class="s s156">What programmers in a hundred years will be looking for, most of
all, is a language where you can throw together an unbelievably
inefficient version 1 of a program with the least possible
effort.</span>  <span class="s s157">At least, that's how we'd describe it in present-day
terms.  What they'll say is that they want a language that's
easy to program in.</span>
   </p>
   <p>
    <span class="s s159">Inefficient software isn't gross.</span>  <span class="s s160">What's gross is a language
that makes programmers do needless work.</span>  <span class="s s161">Wasting programmer time
is the true inefficiency, not wasting machine time.</span>  <span class="s s162">This will
become ever more clear as computers get faster.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s164">I think getting rid of strings is already something we
could bear to think about.</span><span class="s s165">  We did it in
    <a target="_blank" href="http://paulgraham.com/arc.html">
     Arc
    </a>
    , and it seems
to be a win;  some operations that would be awkward to
describe as regular expressions can be described
easily as recursive functions.</span>
   </p>
   <p>
    <span class="s s167">How far will this flattening of data structures go?</span>  <span class="s s168">I can think
of possibilities that shock even me, with my conscientiously broadened
mind.</span>  <span class="s s169">Will we get rid of arrays, for example?</span>  <span class="s s170">After all, they're
just a subset of hash tables where the keys are vectors of
integers.</span>   <span class="s s171">Will we replace hash tables themselves with lists?</span>
   </p>
   <p>
    <span class="s s173">There are more shocking prospects even than that.</span>  <span class="s s174">The Lisp
that McCarthy described in 1960, for example, didn't
have numbers.</span>  <span class="s s175">Logically, you don't need to have a separate notion
of numbers, because you can represent them as lists:  the integer
n could be represented as a list of n elements.</span>  <span class="s s176">You can do math this
way.</span>  <span class="s s177">It's just unbearably inefficient.</span>
   </p>
   <p>
    <span class="s s179">No one actually proposed implementing numbers as lists in
practice.</span>  <span class="s s180">In fact, McCarthy's 1960 paper was not, at the time,
intended to be implemented at all.</span><span class="s s181">  It was a
    <a target="_blank" href="http://paulgraham.com/rootsoflisp.html">
     theoretical exercise
    </a>
    ,
an attempt to create a more elegant alternative to the Turing
Machine.</span>  <span class="s s182">When someone did, unexpectedly, take this paper and
translate it into a working Lisp interpreter, numbers certainly
weren't represented as lists; they were represented in binary,
as in every other language.</span>
   </p>
   <p>
    <span class="s s184">Could a programming language go so far as to get rid of numbers
as a fundamental data type?</span>  <span class="s s185">I ask this not so much as a serious
question as as a way to play chicken with the future.</span>  <span class="s s186">It's like
the hypothetical case of an irresistible force meeting an 
immovable object-- here, an unimaginably inefficient
implementation meeting unimaginably great resources.</span>
<span class="s s187">I don't see why not.</span>  <span class="s s188">The future is pretty long.</span>  <span class="s s189">If there's
something we can do to decrease the number of axioms in the core
language, that would seem to be the side to bet on as t approaches
infinity.</span>  <span class="s s190">If the idea still seems unbearable in a hundred years,
maybe it won't in a thousand.</span>
   </p>
   <p>
    <span class="s s192">Just to be clear about this, I'm not proposing that all numerical
calculations would actually be carried out using lists.</span>  <span class="s s193">I'm proposing
that the core language, prior to any additional notations about
implementation, be defined this way.</span>  <span class="s s194">In practice any program
that wanted to do any amount of math would probably represent
numbers in binary, but this would be an optimization, not part of
the core language semantics.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s196">Another way to burn up cycles is to have many layers of
software between the application and the hardware.</span>  <span class="s s197">This too is
a trend we see happening already: many recent languages are
compiled into byte code.</span>  <span class="s s198">Bill Woods once told me that,
as a rule of thumb, each layer of interpretation costs a
factor of 10 in speed.</span>  <span class="s s199">This extra cost buys you flexibility.</span>
   </p>
   <p>
    <span class="s s201">The very first version of Arc was an extreme case of this sort
of multi-level slowness, with corresponding benefits.</span>  <span class="s s202">It
was a classic "metacircular" interpreter written
on top of Common Lisp, with a definite family resemblance
to the eval function defined in McCarthy's original Lisp paper.</span>
<span class="s s203">The whole thing was only a couple hundred lines of
code, so it was very easy to understand and change.</span>  <span class="s s204">The 
Common Lisp we used, CLisp, itself runs on top
of a byte code interpreter.</span>  <span class="s s205">So here we had two levels of
interpretation, one of them (the top one) shockingly inefficient,
and the language was usable.</span>  <span class="s s206">Barely usable, I admit, but
usable.</span>
   </p>
   <p>
    <span class="s s208">Writing software as multiple layers is a powerful technique
even within applications.</span>  <span class="s s209">Bottom-up programming means writing
a program as a series of layers, each of which serves as a
language for the one above.</span>  <span class="s s210">This approach tends to yield
smaller, more flexible programs.  It's also the best route to   
that holy grail, reusability.</span>  <span class="s s211">A language is by definition
reusable.</span>  <span class="s s212">The more
of your application you can push down into a language for writing
that type of application, the more of your software will be 
reusable.</span>
   </p>
   <p>
    <span class="s s214">Somehow the idea of reusability got attached
to object-oriented programming in the 1980s, and no amount of
evidence to the contrary seems to be able to shake it free.</span>  <span class="s s215">But
although some object-oriented software is reusable, what makes
it reusable is its bottom-upness, not its object-orientedness.</span>
<span class="s s216">Consider libraries: they're reusable because they're language,
whether they're written in an object-oriented style or not.</span>
   </p>
   <p><span class="s s218">
    I don't predict the demise of object-oriented programming, by the
way.  Though I don't think it has much to offer good programmers,
except in certain specialized domains, it is irresistible to   
large organizations.  Object-oriented programming
offers a sustainable way to write spaghetti code.  It lets you accrete
programs as a series of patches.
    </span><!--, without the effort of understanding, 
or the risk of breaking, existing code. --><span class="s s219">
    Large organizations
always tend to develop software this way, and I expect this
to be as true in a hundred years as it is today.
   </span></p>
   <p>
   </p>
   <p>
    <span class="s s220">As long as we're talking about the future, we had better
talk about parallel computation, because that's where this 
idea seems to live.</span>  <span class="s s221">That is, no matter when you're talking, parallel
computation seems to be something that is going to happen
in the future.</span>
   </p>
   <p>
    <span class="s s223">Will the future ever catch up with it?</span>  <span class="s s224">People have been
talking about parallel computation as something imminent 
for at least 20
years, and it hasn't affected programming practice much so far.</span>
<span class="s s225">Or hasn't it?</span>  <span class="s s226">Already
chip designers have to think about it, and so must
people trying to write systems software on multi-cpu computers.</span>
   </p>
   <p>
    <span class="s s228">The real question is, how far up the ladder of abstraction will
parallelism go?</span>
<span class="s s229">In a hundred years will it affect even application programmers?</span>  <span class="s s230">Or
will it be something that compiler writers think about, but
which is usually invisible in the source code of applications?</span>
   </p>
   <p>
    <span class="s s232">One thing that does seem likely is that most opportunities for
parallelism will be wasted.</span>  <span class="s s233">This is a special case of my more   
general prediction that most of the extra computer power we're
given will go to waste.</span>  <span class="s s234">I expect that, as with the stupendous
speed of the underlying hardware, parallelism will be something
that is available if you ask for it explicitly, but ordinarily
not used.</span>  <span class="s s235">This implies that the kind of parallelism we have in
a hundred years will not, except in special applications, be
massive parallelism.</span>  <span class="s s236">I expect for
ordinary programmers it will be more like being able to fork off
processes that all end up running in parallel.</span>
   </p>
   <p>
    <span class="s s238">And this will, like asking for specific implementations of data
structures, be something that you do fairly late in the life of a
program, when you try to optimize it.</span>  <span class="s s239">Version 1s will ordinarily
ignore any advantages to be got from parallel computation, just
as they will ignore advantages to be got from specific representations
of data.</span>
   </p>
   <p>
    <span class="s s241">Except in special kinds of applications, parallelism won't
pervade the programs that are written in a hundred years.</span>  <span class="s s242">It would be
premature optimization if it did.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s244">How many programming languages will there
be in a hundred years?</span>  <span class="s s245">There seem to be a huge number of new
programming languages lately.</span>  <span class="s s246">Part of the reason is that
faster hardware has allowed programmers to make different
tradeoffs between speed and convenience, depending on the
application.</span>  <span class="s s247">If this is a real trend, the hardware we'll  
have in a hundred years should only increase it.</span>
   </p>
   <p>
    <span class="s s249">And yet there may be only a few widely-used languages in a
hundred years.</span>  <span class="s s250">Part of the reason I say this
is optimism: it seems that, if you did a really good job,
you could make a language that was ideal for writing a   
slow version 1, and yet with the right optimization advice
to the compiler, would also yield very fast code when necessary.</span>
<span class="s s251">So, since I'm optimistic, I'm going to predict that despite
the huge gap they'll have between acceptable and maximal
efficiency, programmers in a hundred years will have languages 
that can span most of it.</span>
   </p>
   <p>
    <span class="s s253">As this gap widens, profilers will become increasingly important.</span>
<span class="s s254">Little attention is paid to profiling now.</span>  <span class="s s255">Many people still
seem to believe that the way to get fast applications is to
write compilers that generate fast code.</span>  <span class="s s256">As the gap between    
acceptable and maximal performance widens, it will become
increasingly clear that the way to get fast applications is   
to have a good guide from one to the other.</span>
   </p>
   <p>
    <span class="s s258">When I say there may only be a few languages, I'm not including
domain-specific "little languages".</span>  <span class="s s259">I think such embedded languages
are a great idea, and I expect them to proliferate.</span>  <span class="s s260">But I expect
them to be written as thin enough skins that users can see
the general-purpose language underneath.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s262">Who will design the languages of the future?</span>  <span class="s s263">One of the most exciting
trends in the last ten years has been the rise of open-source  
languages like Perl, Python, and Ruby.</span>
<span class="s s264">Language design is being taken over by hackers.</span>  <span class="s s265">The results
so far are messy, but encouraging.</span>  <span class="s s266">There are some stunningly  
novel ideas in Perl, for example.</span> <span class="s s267">Many are stunningly bad, but
that's always true of ambitious efforts.</span>  <span class="s s268">At its current rate
of mutation, God knows what Perl might evolve into in a hundred
years.</span>
   </p>
   <p>
    <span class="s s270">It's not true that those who can't do, teach (some of the best
hackers I know are professors), but it is true that there are a
lot of things that those who teach can't do.</span><span class="s s271">
    <a target="_blank" href="http://paulgraham.com/desres.html">
     Research
    </a>
    imposes
constraining caste restrictions.</span>  <span class="s s272">In any academic
field there are topics that are ok to work on and others that
aren't.</span>  <span class="s s273">Unfortunately the distinction between acceptable and
forbidden topics is usually based on how intellectual
the work sounds when described in research papers, rather than
how important it is for getting good results.</span>  <span class="s s274">The extreme case
is probably literature; people studying literature rarely  
say anything that would be of the slightest use to those
producing it.</span>
   </p>
   <p>
    <span class="s s276">Though the situation is better in the sciences,
the overlap between the kind of work you're allowed to do and the
kind of work that yields good languages is distressingly small.</span>
<span class="s s277">(Olin Shivers has grumbled eloquently
about this.</span><span class="s s278">)  For example, types seem to be an inexhaustible source
of research papers, despite the fact that static typing
seems to preclude true macros-- without which, in my opinion, no
language is worth using.</span>
   </p>
   <p>
    <span class="s s280">The trend is not merely toward languages being developed
as open-source projects rather than "research", but toward
languages being designed by the application programmers who need
to use them, rather than by compiler writers.</span>  <span class="s s281">This seems a good
trend and I expect it to continue.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s283">Unlike physics in a hundred years, which is almost necessarily
impossible to predict, I think it may be possible in principle
to design a language now that would appeal to users in a hundred
years.</span>
   </p>
   <p>
    <span class="s s285">One way to design a language is to just write down the program
you'd like to be able to write, regardless of whether there 
is a compiler that can translate it or hardware that can run it.</span>
<span class="s s286">When you do this you can assume unlimited resources.</span>  <span class="s s287">It seems
like we ought to be able to imagine unlimited resources as well
today as in a hundred years.</span>
   </p>
   <p>
    <span class="s s289">What program would one like to write?</span>  <span class="s s290">Whatever is least work.</span><span class="s s291">
Except not quite: whatever
    <i>
     would be
    </i>
    least work if your ideas about
programming weren't already influenced by the languages you're 
currently used to.</span>  <span class="s s292">Such influence can be so pervasive that   
it takes a great effort to overcome it.</span>  <span class="s s293">You'd think it would
be obvious to creatures as lazy as us how to express a program
with the least effort.</span><span class="s s294">  In fact, our ideas about what's possible
tend to be so
    <a target="_blank" href="http://paulgraham.com/avg.html">
     limited
    </a>
    by whatever language we think in  that
easier formulations of programs seem very surprising.</span>  <span class="s s295">They're
something you have to discover, not something you naturally
sink into.</span>
   </p>
   <p><span class="s s297">
    One helpful trick here
is to use the
    <a target="_blank" href="http://paulgraham.com/power.html">
     length
    </a>
    of the program as an approximation for
how much work it is to write.</span>  <span class="s s298">Not the length in characters,
of course, but the length in distinct syntactic elements-- basically,
the size of the parse tree.</span>  <span class="s s299">It may not be quite true that
the shortest program is the least work to write, but it's
close enough that you're better off aiming for the solid
target of brevity than the fuzzy, nearby one of least work.</span>
<span class="s s300">Then the algorithm for language design becomes: look at a program
and ask, is there any way to write this that's shorter?</span>
   </p>
   <p>
    <span class="s s302">In practice, writing programs in an imaginary hundred-year
language will work to varying degrees depending
on how close you are to the core.</span>  <span class="s s303">Sort routines you can
write now.</span>  <span class="s s304">But it would be
hard to predict now what kinds of libraries might be needed in
a hundred years.</span>  <span class="s s305">Presumably many libraries will be for domains that
don't even exist yet.</span>  <span class="s s306">If SETI@home works, for example, we'll  
need libraries for communicating with aliens.</span>  <span class="s s307">Unless of course
they are sufficiently advanced that they already communicate
in XML.</span>
   </p>
   <p>
    <span class="s s309">At the other extreme, I think you might be able to design the
core language today.</span>  <span class="s s310">In fact, some might argue that it was already
mostly designed in 1958.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s312">If the hundred year language were available today, would we
want to program in it?</span>  <span class="s s313">One way to answer this question is to
look back.</span>  <span class="s s314">If present-day programming languages had been available
in 1960, would anyone have wanted to use them?</span>
   </p>
   <p>
    <span class="s s316">In some ways, the answer is no.</span>  <span class="s s317">Languages today assume
infrastructure that didn't exist in 1960.</span>  <span class="s s318">For example, a language
in which indentation is significant, like Python, would not
work very well on printer terminals.</span>  <span class="s s319">But putting such problems
aside-- assuming, for example, that programs were all just
written on paper-- would programmers of the 1960s have liked
writing programs in the languages we use now?</span>
   </p>
   <p>
    <span class="s s321">I think so.</span>
<span class="s s322">Some of the less imaginative ones,
who had artifacts of early languages built into their ideas of  
what a program was, might have had trouble.</span>  <span class="s s323">(How can you manipulate
data without doing pointer arithmetic?</span>  <span class="s s324">How can you implement 
flow charts without gotos?</span><span class="s s325">)  But I think the smartest programmers
would have had no trouble making the most of present-day
languages, if they'd had them.</span>
   </p>
   <p>
    <span class="s s327">If we had the hundred-year language now, it would at least make a
great pseudocode.</span>  <span class="s s328">What about using it to write software?</span>   
<span class="s s329">Since the hundred-year language
will need to generate fast code for some applications, presumably
it could generate code efficient enough to run acceptably well
on our hardware.</span>  <span class="s s330">We might have to give more optimization advice
than users in a hundred years, but it still might be a net win.</span>
   </p>
   <p>
   </p>
   <p>
    <span class="s s332">Now we have two ideas that, if you combine them, suggest interesting
possibilities: (1) the hundred-year language could, in principle, be
designed today, and (2) such a language, if it existed, might be good to
program in today.</span>  <span class="s s333">When you see these ideas laid out like that,
it's hard not to think, why not try writing the hundred-year language
now?</span>
   </p>
   <p>
    <span class="s s335">When you're working on language design, I think it is good to
have such a target and to keep it consciously in mind.</span>  <span class="s s336">When you
learn to drive, one of the principles they teach you is to
align the car not by lining up the hood with the stripes painted
on the road, but by aiming at some point in the distance.</span>  <span class="s s337">Even
if all you care about is what happens in the next ten feet, this
is the right answer.</span>  <span class="s s338">I
think we can and should do the same thing with programming languages.</span>
   </p>
   <p>
   </p>
   <h3><span class="s s340">
    Notes
   </span></h3>
   <p>
    <span class="s s341">I believe Lisp Machine Lisp was the first language to embody
the principle that declarations (except those of dynamic variables)
were merely optimization advice,
and would not change the meaning of a correct program.</span>  <span class="s s342">Common Lisp
seems to have been the first to state this explicitly.</span>
   </p>
   <h3>
    <span class="s s344">Thanks
    to Trevor Blackwell, Robert Morris, and Dan Giffin for
reading drafts of this, and to Guido van Rossum, Jeremy Hylton, and the
rest of the Python crew for inviting me to speak at PyCon.</span>
   </h3>
  
  <p>
   <br clear="all"></p><p><span class="s s346">
    This essay was originally published at
    <a target="_blank" href="http://www.paulgraham.com/hundred.html?utm_source=pgebook">
     paulgraham.com
    </a>
    </span></p><p>
    </p>
   
  
 </body></html>
